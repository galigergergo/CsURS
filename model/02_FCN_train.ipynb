{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed402e43-c224-4c07-8b59-07eff24cf8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "import torch\n",
    "import torchmetrics\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "sys.path.append('./')\n",
    "from src.utils.data_utils import read_dataset, read_dataset_config\n",
    "from src.trainers.AETrainer import AEFCNTrainer\n",
    "\n",
    "DATA_PATH = './data'\n",
    "FILE_NAME_TRAIN = 'BP_safety_network_master_NN_train.csv'\n",
    "FILE_NAME_TEST = 'BP_safety_network_master_NN_test.csv'\n",
    "FILE_NAME_CONF = 'BP_safety_network_master_NN_config.csv'\n",
    "AE_RUN_ID = 'e5a5b25fc25f4435bd9177664c21ff9a'\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:8080')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7197ff3a-a079-4ada-a5db-8fed82ba5067",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mlflow.set_experiment('02_FCN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2583a42-d126-4d9c-9bfa-33814d84dca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/02 12:50:57 WARNING mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics because creating `GPUMonitor` failed with error: Failed to initialize NVML, skip logging GPU metrics: NVML Shared Library Not Found.\n",
      "2025/10/02 12:50:57 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "C:\\Users\\galig\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|█████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 68.29it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:12<00:00, 15.89it/s]\n",
      "2025/10/02 12:51:28 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/10/02 12:51:28 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run mercurial-quail-875 at: http://127.0.0.1:8080/#/experiments/196378654275874061/runs/864acd819e184220b6ca130a66e2e061\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/196378654275874061\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(log_system_metrics=True) as run:\n",
    "    # Seed random generators to ensure deterministic experiments\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # Define PyTorch device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Read and log train, validation, test datasets and dataset config file\n",
    "    X_train, y_train, _ = read_dataset(DATA_PATH, FILE_NAME_TRAIN, targets='rs_crashes_2324', device=device)\n",
    "    X_test, y_test, non_accident_dim = read_dataset(DATA_PATH, FILE_NAME_TEST, targets='rs_crashes_2324', device=device)\n",
    "    df_conf = read_dataset_config(DATA_PATH, FILE_NAME_CONF)\n",
    "    \n",
    "    # Load trained autoencoder from MLflow\n",
    "    autoencoder = mlflow.pytorch.load_model(f'runs:/{AE_RUN_ID}/{MlflowClient().list_artifacts(AE_RUN_ID, \"models\")[0].path}')\n",
    "    \n",
    "    # Specify and log training parameters\n",
    "    params = {\n",
    "        'autoencoder': autoencoder,\n",
    "        'inp_dim': X_train.shape[1] - non_accident_dim + autoencoder.enc_dim,\n",
    "        'learning_rate': 1e-2\n",
    "    }\n",
    "    mlflow.log_params(params.copy())\n",
    "\n",
    "    # Define, train and evaluate model\n",
    "    trainer = AEFCNTrainer(**params)\n",
    "    trainer.train(X_train, y_train, X_test, y_test, epochs=200, min_max_norms=(df_conf['rs_crashes_min'][0], df_conf['rs_crashes_max'][0]))\n",
    "    trainer.evaluate(X_test, y_test, 'test', min_max_norms=(df_conf['rs_crashes_min'][0], df_conf['rs_crashes_max'][0]))\n",
    "    trainer.evaluate(X_train, y_train, 'train', torch.nn.L1Loss(), 'mae', min_max_norms=(df_conf['rs_crashes_min'][0], df_conf['rs_crashes_max'][0]))\n",
    "    trainer.evaluate(X_test, y_test, 'test', torch.nn.L1Loss(), 'mae', min_max_norms=(df_conf['rs_crashes_min'][0], df_conf['rs_crashes_max'][0]))\n",
    "    trainer.evaluate(X_train, y_train, 'train', torchmetrics.regression.MeanAbsolutePercentageError(), 'mape',\n",
    "                     min_max_norms=(df_conf['rs_crashes_min'][0], df_conf['rs_crashes_max'][0]), proc_func=lambda x: x+1)\n",
    "    trainer.evaluate(X_test, y_test, 'test', torchmetrics.regression.MeanAbsolutePercentageError(), 'mape',\n",
    "                     min_max_norms=(df_conf['rs_crashes_min'][0], df_conf['rs_crashes_max'][0]), proc_func=lambda x: x+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
